{"code":"/**\n * Ultra-Precision Predictor\n *\n * Advanced ensemble predictor targeting sub-1% error rates through\n * sophisticated feature engineering and model combination.\n */\nimport { ValidationUtils } from '../utils/ValidationUtils';\nimport { StatisticsUtils } from '../utils/StatisticsUtils';\nimport { MathUtils } from '../utils/MathUtils';\nimport { DEFAULT_PREDICTOR_OPTIONS } from '../config/defaults';\n/**\n * Ultra-precision predictor implementation\n */\nexport class UltraPrecisionPredictor {\n    constructor(options = {}) {\n        this.models = [];\n        this.isTrained = false;\n        this.featureImportance = [];\n        this.trainingMetrics = null;\n        this.lastConfidence = 0;\n        this.modelWeights = [];\n        this.options = {\n            ...DEFAULT_PREDICTOR_OPTIONS,\n            ...options\n        };\n    }\n    /**\n     * Train the ultra-precision predictor\n     */\n    async train(data) {\n        console.log(`ðŸš€ Training Ultra-Precision Predictor with ${data.length} samples...`);\n        // Validate training data\n        const validation = ValidationUtils.validateTrainingData(data);\n        if (!validation.isValid) {\n            throw new Error(`Training data validation failed: ${validation.errors.map(e => e.message).join(', ')}`);\n        }\n        // Prepare features and targets\n        const { features, targets } = this.prepareTrainingData(data);\n        console.log(`âœ¨ Prepared ${features.length} samples with ${features[0]?.length || 0} features`);\n        // Split data for training and validation\n        const { trainX, trainY, testX, testY } = this.splitData(features, targets);\n        // Train ensemble of models\n        const startTime = Date.now();\n        await this.trainEnsemble(trainX, trainY);\n        const trainingTime = Date.now() - startTime;\n        // Validate performance\n        const predictions = await this.predictBatch(testX);\n        this.trainingMetrics = this.calculateMetrics(predictions, testY);\n        // Calculate feature importance\n        this.calculateFeatureImportance(features[0]?.length || 0);\n        console.log(`ðŸ“Š Training completed in ${trainingTime}ms:`);\n        console.log(`   MAE: ${(this.trainingMetrics.mae * 100).toFixed(3)}%`);\n        console.log(`   RMSE: ${(this.trainingMetrics.rmse * 100).toFixed(3)}%`);\n        console.log(`   RÂ²: ${this.trainingMetrics.r2.toFixed(4)}`);\n        console.log(`   Directional Accuracy: ${(this.trainingMetrics.directionalAccuracy * 100).toFixed(1)}%`);\n        this.isTrained = true;\n        // Check if we achieved target error rate\n        if (this.trainingMetrics.mae <= this.options.targetErrorRate) {\n            console.log(`ðŸŽ¯ Target error rate achieved: ${(this.trainingMetrics.mae * 100).toFixed(3)}% <= ${(this.options.targetErrorRate * 100).toFixed(1)}%`);\n        }\n        else {\n            console.log(`âš ï¸  Target error rate not achieved. Consider increasing ensemble size or feature count.`);\n        }\n        return {\n            trainingMetrics: this.trainingMetrics,\n            validationMetrics: this.trainingMetrics, // Same for now\n            trainingTime,\n            featureCount: features[0]?.length || 0,\n            featureImportance: [...this.featureImportance]\n        };\n    }\n    /**\n     * Make ultra-precise prediction\n     */\n    async predict(features) {\n        if (!this.isTrained) {\n            throw new Error('Model must be trained before making predictions');\n        }\n        const validation = ValidationUtils.validateFeatures(features);\n        if (!validation.isValid) {\n            throw new Error(`Feature validation failed: ${validation.errors.map(e => e.message).join(', ')}`);\n        }\n        // Get ensemble predictions\n        const predictions = this.models.map((model, index) => {\n            try {\n                return this.predictWithModel(model, features, index);\n            }\n            catch (error) {\n                console.warn(`Model ${index} prediction failed:`, error);\n                return 0;\n            }\n        });\n        // Calculate weighted average with confidence\n        const weightedPrediction = this.combinepredictions(predictions);\n        // Calculate prediction confidence\n        this.lastConfidence = this.calculatePredictionConfidence(predictions);\n        return weightedPrediction;\n    }\n    /**\n     * Batch prediction for multiple samples\n     */\n    async predictBatch(featuresMatrix) {\n        if (!this.isTrained) {\n            throw new Error('Model must be trained before making predictions');\n        }\n        const predictions = [];\n        for (const features of featuresMatrix) {\n            const prediction = await this.predict(features);\n            predictions.push(prediction);\n        }\n        return predictions;\n    }\n    /**\n     * Get prediction confidence (0-1)\n     */\n    getConfidence() {\n        return this.lastConfidence;\n    }\n    /**\n     * Get feature importance scores\n     */\n    getFeatureImportance() {\n        return [...this.featureImportance];\n    }\n    /**\n     * Get training metrics\n     */\n    getTrainingMetrics() {\n        return this.trainingMetrics;\n    }\n    /**\n     * Check if model is trained\n     */\n    isModelTrained() {\n        return this.isTrained;\n    }\n    /**\n     * Save model to JSON string\n     */\n    async saveModel() {\n        if (!this.isTrained) {\n            throw new Error('Cannot save untrained model');\n        }\n        const modelData = {\n            version: '2.0.0',\n            options: this.options,\n            models: this.models.map(model => this.serializeModel(model)),\n            modelWeights: this.modelWeights,\n            featureImportance: this.featureImportance,\n            trainingMetrics: this.trainingMetrics,\n            timestamp: new Date().toISOString()\n        };\n        return JSON.stringify(modelData, null, 2);\n    }\n    /**\n     * Load model from JSON string\n     */\n    async loadModel(modelJson) {\n        try {\n            const modelData = JSON.parse(modelJson);\n            this.options = { ...this.options, ...modelData.options };\n            this.modelWeights = modelData.modelWeights || [];\n            this.featureImportance = modelData.featureImportance || [];\n            this.trainingMetrics = modelData.trainingMetrics;\n            // Reconstruct models\n            this.models = modelData.models.map((serializedModel) => this.deserializeModel(serializedModel));\n            this.isTrained = this.models.length > 0;\n            console.log(`âœ… Model loaded successfully (${this.models.length} ensemble models)`);\n        }\n        catch (error) {\n            throw new Error(`Failed to load model: ${error}`);\n        }\n    }\n    /**\n     * Prepare training data from raw data\n     */\n    prepareTrainingData(data) {\n        const features = [];\n        const targets = [];\n        for (let i = 0; i < data.length - 1; i++) {\n            const current = data[i];\n            const next = data[i + 1];\n            // Use provided features or generate basic ones\n            let featureVector;\n            if (current.features && current.features.length > 0) {\n                featureVector = current.features;\n            }\n            else {\n                // Generate basic features from OHLCV data\n                featureVector = this.generateBasicFeatures(data, i);\n            }\n            // Calculate target (next period return)\n            const target = current.target !== undefined ?\n                current.target :\n                (next.close - current.close) / current.close;\n            if (featureVector.length > 0 && isFinite(target)) {\n                features.push(featureVector);\n                targets.push(target);\n            }\n        }\n        return { features, targets };\n    }\n    /**\n     * Generate basic features from OHLCV data\n     */\n    generateBasicFeatures(data, index) {\n        const features = [];\n        const current = data[index];\n        // Basic price features\n        features.push((current.high - current.low) / current.close, // High-low range\n        (current.close - current.open) / current.open, // Open-close return\n        current.volume / 1000000 // Normalized volume\n        );\n        // Simple moving averages (if enough history)\n        const lookbacks = [5, 10, 20];\n        for (const lookback of lookbacks) {\n            if (index >= lookback) {\n                const prices = data.slice(index - lookback + 1, index + 1).map(d => d.close);\n                const sma = StatisticsUtils.mean(prices);\n                features.push((current.close - sma) / sma);\n            }\n            else {\n                features.push(0);\n            }\n        }\n        // Simple returns (if enough history)\n        for (let lag = 1; lag <= 5; lag++) {\n            if (index >= lag) {\n                const prevClose = data[index - lag].close;\n                features.push((current.close - prevClose) / prevClose);\n            }\n            else {\n                features.push(0);\n            }\n        }\n        return features;\n    }\n    /**\n     * Split data into training and testing sets\n     */\n    splitData(features, targets) {\n        const n = features.length;\n        const trainSize = Math.floor(n * this.options.trainingRatio);\n        const trainX = features.slice(0, trainSize);\n        const testX = features.slice(trainSize);\n        const trainY = targets.slice(0, trainSize);\n        const testY = targets.slice(trainSize);\n        return { trainX, trainY, testX, testY };\n    }\n    /**\n     * Train ensemble of models\n     */\n    async trainEnsemble(trainX, trainY) {\n        this.models = [];\n        this.modelWeights = [];\n        for (let i = 0; i < this.options.ensembleSize; i++) {\n            console.log(`Training model ${i + 1}/${this.options.ensembleSize}...`);\n            const model = await this.trainSingleModel(trainX, trainY, i);\n            const weight = this.calculateModelWeight(model, trainX, trainY);\n            this.models.push(model);\n            this.modelWeights.push(weight);\n        }\n        // Normalize weights\n        const totalWeight = StatisticsUtils.sum(this.modelWeights);\n        if (totalWeight > 0) {\n            this.modelWeights = this.modelWeights.map(w => w / totalWeight);\n        }\n        else {\n            this.modelWeights = new Array(this.models.length).fill(1 / this.models.length);\n        }\n    }\n    /**\n     * Train a single model in the ensemble\n     */\n    async trainSingleModel(trainX, trainY, modelIndex) {\n        // Bootstrap sampling for diversity\n        const { sampledX, sampledY } = this.bootstrapSample(trainX, trainY, modelIndex);\n        // Simple linear regression model (in production, use more sophisticated models)\n        const model = this.trainLinearRegression(sampledX, sampledY);\n        return {\n            type: 'linear',\n            coefficients: model.coefficients,\n            intercept: model.intercept,\n            seed: modelIndex * 42\n        };\n    }\n    /**\n     * Train a simple linear regression model\n     */\n    trainLinearRegression(X, y) {\n        const n = X.length;\n        const p = X[0]?.length || 0;\n        if (n === 0 || p === 0) {\n            return { coefficients: [], intercept: 0 };\n        }\n        // Add intercept column\n        const XWithIntercept = X.map(row => [1, ...row]);\n        // Normal equation: Î² = (X'X)^(-1)X'y\n        // Simplified implementation for demonstration\n        const coefficients = new Array(p).fill(0);\n        let intercept = StatisticsUtils.mean(y);\n        // Simple gradient descent approximation\n        for (let feature = 0; feature < p; feature++) {\n            const featureValues = X.map(row => row[feature]);\n            const correlation = MathUtils.correlation(featureValues, y);\n            coefficients[feature] = correlation * 0.1; // Simplified coefficient\n        }\n        return { coefficients, intercept };\n    }\n    /**\n     * Bootstrap sampling for ensemble diversity\n     */\n    bootstrapSample(X, y, seed) {\n        const n = X.length;\n        const sampledX = [];\n        const sampledY = [];\n        // Use seed for reproducible randomness\n        let random = seed;\n        const nextRandom = () => {\n            random = (random * 9301 + 49297) % 233280;\n            return random / 233280;\n        };\n        for (let i = 0; i < n; i++) {\n            const randomIndex = Math.floor(nextRandom() * n);\n            sampledX.push([...X[randomIndex]]);\n            sampledY.push(y[randomIndex]);\n        }\n        return { sampledX, sampledY };\n    }\n    /**\n     * Calculate model weight based on performance\n     */\n    calculateModelWeight(model, X, y) {\n        const predictions = X.map(features => this.predictWithModel(model, features, 0));\n        const mse = StatisticsUtils.mean(predictions.map((pred, i) => Math.pow(pred - y[i], 2)));\n        // Weight inversely proportional to error\n        return mse > 0 ? 1 / (1 + mse) : 1;\n    }\n    /**\n     * Make prediction with a single model\n     */\n    predictWithModel(model, features, modelIndex) {\n        if (model.type === 'linear') {\n            let prediction = model.intercept;\n            for (let i = 0; i < Math.min(features.length, model.coefficients.length); i++) {\n                prediction += features[i] * model.coefficients[i];\n            }\n            return prediction;\n        }\n        return 0;\n    }\n    /**\n     * Combine predictions from ensemble\n     */\n    combinepredictions(predictions) {\n        if (predictions.length === 0)\n            return 0;\n        // Weighted average\n        let weightedSum = 0;\n        let totalWeight = 0;\n        for (let i = 0; i < predictions.length; i++) {\n            const weight = this.modelWeights[i] || (1 / predictions.length);\n            weightedSum += predictions[i] * weight;\n            totalWeight += weight;\n        }\n        return totalWeight > 0 ? weightedSum / totalWeight : StatisticsUtils.mean(predictions);\n    }\n    /**\n     * Calculate prediction confidence based on ensemble agreement\n     */\n    calculatePredictionConfidence(predictions) {\n        if (predictions.length === 0)\n            return 0;\n        const mean = StatisticsUtils.mean(predictions);\n        const std = StatisticsUtils.standardDeviation(predictions);\n        // Confidence inversely related to standard deviation\n        const normalizedStd = std / (Math.abs(mean) + 1e-8);\n        const confidence = Math.max(0, Math.min(1, 1 - normalizedStd));\n        return confidence;\n    }\n    /**\n     * Calculate feature importance\n     */\n    calculateFeatureImportance(featureCount) {\n        // Simplified feature importance calculation\n        this.featureImportance = new Array(featureCount).fill(0);\n        // Calculate average absolute coefficients across models\n        for (const model of this.models) {\n            if (model.coefficients) {\n                for (let i = 0; i < Math.min(featureCount, model.coefficients.length); i++) {\n                    this.featureImportance[i] += Math.abs(model.coefficients[i]);\n                }\n            }\n        }\n        // Normalize\n        const total = StatisticsUtils.sum(this.featureImportance);\n        if (total > 0) {\n            this.featureImportance = this.featureImportance.map(imp => imp / total);\n        }\n    }\n    /**\n     * Calculate model performance metrics\n     */\n    calculateMetrics(predictions, actual) {\n        const n = Math.min(predictions.length, actual.length);\n        if (n === 0) {\n            return {\n                mae: 1,\n                mse: 1,\n                rmse: 1,\n                r2: 0,\n                directionalAccuracy: 0.5,\n                sampleCount: 0\n            };\n        }\n        const pred = predictions.slice(0, n);\n        const act = actual.slice(0, n);\n        // Mean Absolute Error\n        const mae = StatisticsUtils.mean(pred.map((p, i) => Math.abs(p - act[i])));\n        // Root Mean Square Error\n        const mse = StatisticsUtils.mean(pred.map((p, i) => Math.pow(p - act[i], 2)));\n        const rmse = Math.sqrt(mse);\n        // R-squared\n        const actualMean = StatisticsUtils.mean(act);\n        const totalSumSquares = StatisticsUtils.sum(act.map(a => Math.pow(a - actualMean, 2)));\n        const residualSumSquares = StatisticsUtils.sum(pred.map((p, i) => Math.pow(act[i] - p, 2)));\n        const r2 = totalSumSquares > 0 ? 1 - (residualSumSquares / totalSumSquares) : 0;\n        // Directional Accuracy\n        const correctDirections = pred.filter((p, i) => {\n            return (p > 0 && act[i] > 0) || (p < 0 && act[i] < 0) || (Math.abs(p) < 1e-8 && Math.abs(act[i]) < 1e-8);\n        }).length;\n        const directionalAccuracy = correctDirections / n;\n        return {\n            mae,\n            mse,\n            rmse,\n            r2,\n            directionalAccuracy,\n            sampleCount: n\n        };\n    }\n    /**\n     * Serialize model for saving\n     */\n    serializeModel(model) {\n        return {\n            type: model.type,\n            coefficients: model.coefficients,\n            intercept: model.intercept,\n            seed: model.seed\n        };\n    }\n    /**\n     * Deserialize model for loading\n     */\n    deserializeModel(serializedModel) {\n        return {\n            type: serializedModel.type,\n            coefficients: serializedModel.coefficients || [],\n            intercept: serializedModel.intercept || 0,\n            seed: serializedModel.seed || 0\n        };\n    }\n}\n//# sourceMappingURL=UltraPrecisionPredictor.js.map","references":["C:/Users/Ishaan/OneDrive/Desktop/MeridianLearning/meridianalgo-js/src/types/Prediction.ts","C:/Users/Ishaan/OneDrive/Desktop/MeridianLearning/meridianalgo-js/src/types/MarketData.ts","C:/Users/Ishaan/OneDrive/Desktop/MeridianLearning/meridianalgo-js/src/utils/ValidationUtils.ts","C:/Users/Ishaan/OneDrive/Desktop/MeridianLearning/meridianalgo-js/src/utils/StatisticsUtils.ts","C:/Users/Ishaan/OneDrive/Desktop/MeridianLearning/meridianalgo-js/src/utils/MathUtils.ts","C:/Users/Ishaan/OneDrive/Desktop/MeridianLearning/meridianalgo-js/src/config/defaults.ts"],"map":"{\"version\":3,\"file\":\"UltraPrecisionPredictor.js\",\"sourceRoot\":\"\",\"sources\":[\"../../../../../src/predictors/UltraPrecisionPredictor.ts\"],\"names\":[],\"mappings\":\"AAAA;;;;;GAKG;AAIH,OAAO,EAAE,eAAe,EAAE,MAAM,0BAA0B,CAAC;AAC3D,OAAO,EAAE,eAAe,EAAE,MAAM,0BAA0B,CAAC;AAC3D,OAAO,EAAE,SAAS,EAAE,MAAM,oBAAoB,CAAC;AAC/C,OAAO,EAAE,yBAAyB,EAAE,MAAM,oBAAoB,CAAC;AAE/D;;GAEG;AACH,MAAM,OAAO,uBAAuB;IASlC,YAAY,UAAqC,EAAE;QAP3C,WAAM,GAAU,EAAE,CAAC;QACnB,cAAS,GAAY,KAAK,CAAC;QAC3B,sBAAiB,GAAa,EAAE,CAAC;QACjC,oBAAe,GAAwB,IAAI,CAAC;QAC5C,mBAAc,GAAW,CAAC,CAAC;QAC3B,iBAAY,GAAa,EAAE,CAAC;QAGlC,IAAI,CAAC,OAAO,GAAG;YACb,GAAG,yBAAyB;YAC5B,GAAG,OAAO;SACX,CAAC;IACJ,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,KAAK,CAAC,IAAoB;QAC9B,OAAO,CAAC,GAAG,CAAC,8CAA8C,IAAI,CAAC,MAAM,aAAa,CAAC,CAAC;QAEpF,yBAAyB;QACzB,MAAM,UAAU,GAAG,eAAe,CAAC,oBAAoB,CAAC,IAAI,CAAC,CAAC;QAC9D,IAAI,CAAC,UAAU,CAAC,OAAO,EAAE,CAAC;YACxB,MAAM,IAAI,KAAK,CAAC,oCAAoC,UAAU,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;QAC1G,CAAC;QAED,+BAA+B;QAC/B,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,GAAG,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC,CAAC;QAC7D,OAAO,CAAC,GAAG,CAAC,cAAc,QAAQ,CAAC,MAAM,iBAAiB,QAAQ,CAAC,CAAC,CAAC,EAAE,MAAM,IAAI,CAAC,WAAW,CAAC,CAAC;QAE/F,yCAAyC;QACzC,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,QAAQ,EAAE,OAAO,CAAC,CAAC;QAE3E,2BAA2B;QAC3B,MAAM,SAAS,GAAG,IAAI,CAAC,GAAG,EAAE,CAAC;QAC7B,MAAM,IAAI,CAAC,aAAa,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;QACzC,MAAM,YAAY,GAAG,IAAI,CAAC,GAAG,EAAE,GAAG,SAAS,CAAC;QAE5C,uBAAuB;QACvB,MAAM,WAAW,GAAG,MAAM,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,CAAC;QACnD,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,gBAAgB,CAAC,WAAW,EAAE,KAAK,CAAC,CAAC;QAEjE,+BAA+B;QAC/B,IAAI,CAAC,0BAA0B,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,MAAM,IAAI,CAAC,CAAC,CAAC;QAE1D,OAAO,CAAC,GAAG,CAAC,4BAA4B,YAAY,KAAK,CAAC,CAAC;QAC3D,OAAO,CAAC,GAAG,CAAC,WAAW,CAAC,IAAI,CAAC,eAAe,CAAC,GAAG,GAAG,GAAG,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QACvE,OAAO,CAAC,GAAG,CAAC,YAAY,CAAC,IAAI,CAAC,eAAe,CAAC,IAAI,GAAG,GAAG,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QACzE,OAAO,CAAC,GAAG,CAAC,UAAU,IAAI,CAAC,eAAe,CAAC,EAAE,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;QAC5D,OAAO,CAAC,GAAG,CAAC,4BAA4B,CAAC,IAAI,CAAC,eAAe,CAAC,mBAAmB,GAAG,GAAG,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QAExG,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC;QAEtB,yCAAyC;QACzC,IAAI,IAAI,CAAC,eAAe,CAAC,GAAG,IAAI,IAAI,CAAC,OAAO,CAAC,eAAe,EAAE,CAAC;YAC7D,OAAO,CAAC,GAAG,CAAC,kCAAkC,CAAC,IAAI,CAAC,eAAe,CAAC,GAAG,GAAG,GAAG,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,QAAQ,CAAC,IAAI,CAAC,OAAO,CAAC,eAAe,GAAG,GAAG,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;QACvJ,CAAC;aAAM,CAAC;YACN,OAAO,CAAC,GAAG,CAAC,yFAAyF,CAAC,CAAC;QACzG,CAAC;QAED,OAAO;YACL,eAAe,EAAE,IAAI,CAAC,eAAe;YACrC,iBAAiB,EAAE,IAAI,CAAC,eAAe,EAAE,eAAe;YACxD,YAAY;YACZ,YAAY,EAAE,QAAQ,CAAC,CAAC,CAAC,EAAE,MAAM,IAAI,CAAC;YACtC,iBAAiB,EAAE,CAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC;SAC/C,CAAC;IACJ,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,OAAO,CAAC,QAAkB;QAC9B,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,CAAC;YACpB,MAAM,IAAI,KAAK,CAAC,iDAAiD,CAAC,CAAC;QACrE,CAAC;QAED,MAAM,UAAU,GAAG,eAAe,CAAC,gBAAgB,CAAC,QAAQ,CAAC,CAAC;QAC9D,IAAI,CAAC,UAAU,CAAC,OAAO,EAAE,CAAC;YACxB,MAAM,IAAI,KAAK,CAAC,8BAA8B,UAAU,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;QACpG,CAAC;QAED,2BAA2B;QAC3B,MAAM,WAAW,GAAG,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,EAAE;YACnD,IAAI,CAAC;gBACH,OAAO,IAAI,CAAC,gBAAgB,CAAC,KAAK,EAAE,QAAQ,EAAE,KAAK,CAAC,CAAC;YACvD,CAAC;YAAC,OAAO,KAAK,EAAE,CAAC;gBACf,OAAO,CAAC,IAAI,CAAC,SAAS,KAAK,qBAAqB,EAAE,KAAK,CAAC,CAAC;gBACzD,OAAO,CAAC,CAAC;YACX,CAAC;QACH,CAAC,CAAC,CAAC;QAEH,6CAA6C;QAC7C,MAAM,kBAAkB,GAAG,IAAI,CAAC,kBAAkB,CAAC,WAAW,CAAC,CAAC;QAEhE,kCAAkC;QAClC,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,6BAA6B,CAAC,WAAW,CAAC,CAAC;QAEtE,OAAO,kBAAkB,CAAC;IAC5B,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,YAAY,CAAC,cAA0B;QAC3C,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,CAAC;YACpB,MAAM,IAAI,KAAK,CAAC,iDAAiD,CAAC,CAAC;QACrE,CAAC;QAED,MAAM,WAAW,GAAa,EAAE,CAAC;QAEjC,KAAK,MAAM,QAAQ,IAAI,cAAc,EAAE,CAAC;YACtC,MAAM,UAAU,GAAG,MAAM,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC;YAChD,WAAW,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;QAC/B,CAAC;QAED,OAAO,WAAW,CAAC;IACrB,CAAC;IAED;;OAEG;IACH,aAAa;QACX,OAAO,IAAI,CAAC,cAAc,CAAC;IAC7B,CAAC;IAED;;OAEG;IACH,oBAAoB;QAClB,OAAO,CAAC,GAAG,IAAI,CAAC,iBAAiB,CAAC,CAAC;IACrC,CAAC;IAED;;OAEG;IACH,kBAAkB;QAChB,OAAO,IAAI,CAAC,eAAe,CAAC;IAC9B,CAAC;IAED;;OAEG;IACH,cAAc;QACZ,OAAO,IAAI,CAAC,SAAS,CAAC;IACxB,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,SAAS;QACb,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,CAAC;YACpB,MAAM,IAAI,KAAK,CAAC,6BAA6B,CAAC,CAAC;QACjD,CAAC;QAED,MAAM,SAAS,GAAG;YAChB,OAAO,EAAE,OAAO;YAChB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,IAAI,CAAC,cAAc,CAAC,KAAK,CAAC,CAAC;YAC5D,YAAY,EAAE,IAAI,CAAC,YAAY;YAC/B,iBAAiB,EAAE,IAAI,CAAC,iBAAiB;YACzC,eAAe,EAAE,IAAI,CAAC,eAAe;YACrC,SAAS,EAAE,IAAI,IAAI,EAAE,CAAC,WAAW,EAAE;SACpC,CAAC;QAEF,OAAO,IAAI,CAAC,SAAS,CAAC,SAAS,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;IAC5C,CAAC;IAED;;OAEG;IACH,KAAK,CAAC,SAAS,CAAC,SAAiB;QAC/B,IAAI,CAAC;YACH,MAAM,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;YAExC,IAAI,CAAC,OAAO,GAAG,EAAE,GAAG,IAAI,CAAC,OAAO,EAAE,GAAG,SAAS,CAAC,OAAO,EAAE,CAAC;YACzD,IAAI,CAAC,YAAY,GAAG,SAAS,CAAC,YAAY,IAAI,EAAE,CAAC;YACjD,IAAI,CAAC,iBAAiB,GAAG,SAAS,CAAC,iBAAiB,IAAI,EAAE,CAAC;YAC3D,IAAI,CAAC,eAAe,GAAG,SAAS,CAAC,eAAe,CAAC;YAEjD,qBAAqB;YACrB,IAAI,CAAC,MAAM,GAAG,SAAS,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,eAAoB,EAAE,EAAE,CAC1D,IAAI,CAAC,gBAAgB,CAAC,eAAe,CAAC,CACvC,CAAC;YAEF,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC;YAExC,OAAO,CAAC,GAAG,CAAC,gCAAgC,IAAI,CAAC,MAAM,CAAC,MAAM,mBAAmB,CAAC,CAAC;QACrF,CAAC;QAAC,OAAO,KAAK,EAAE,CAAC;YACf,MAAM,IAAI,KAAK,CAAC,yBAAyB,KAAK,EAAE,CAAC,CAAC;QACpD,CAAC;IACH,CAAC;IAED;;OAEG;IACK,mBAAmB,CAAC,IAAoB;QAC9C,MAAM,QAAQ,GAAe,EAAE,CAAC;QAChC,MAAM,OAAO,GAAa,EAAE,CAAC;QAE7B,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC;YACzC,MAAM,OAAO,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;YACxB,MAAM,IAAI,GAAG,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;YAEzB,+CAA+C;YAC/C,IAAI,aAAuB,CAAC;YAC5B,IAAI,OAAO,CAAC,QAAQ,IAAI,OAAO,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;gBACpD,aAAa,GAAG,OAAO,CAAC,QAAQ,CAAC;YACnC,CAAC;iBAAM,CAAC;gBACN,0CAA0C;gBAC1C,aAAa,GAAG,IAAI,CAAC,qBAAqB,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YACtD,CAAC;YAED,wCAAwC;YACxC,MAAM,MAAM,GAAG,OAAO,CAAC,MAAM,KAAK,SAAS,CAAC,CAAC;gBAC3C,OAAO,CAAC,MAAM,CAAC,CAAC;gBAChB,CAAC,IAAI,CAAC,KAAK,GAAG,OAAO,CAAC,KAAK,CAAC,GAAG,OAAO,CAAC,KAAK,CAAC;YAE/C,IAAI,aAAa,CAAC,MAAM,GAAG,CAAC,IAAI,QAAQ,CAAC,MAAM,CAAC,EAAE,CAAC;gBACjD,QAAQ,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC;gBAC7B,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YACvB,CAAC;QACH,CAAC;QAED,OAAO,EAAE,QAAQ,EAAE,OAAO,EAAE,CAAC;IAC/B,CAAC;IAED;;OAEG;IACK,qBAAqB,CAAC,IAAoB,EAAE,KAAa;QAC/D,MAAM,QAAQ,GAAa,EAAE,CAAC;QAC9B,MAAM,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC;QAE5B,uBAAuB;QACvB,QAAQ,CAAC,IAAI,CACX,CAAC,OAAO,CAAC,IAAI,GAAG,OAAO,CAAC,GAAG,CAAC,GAAG,OAAO,CAAC,KAAK,EAAE,iBAAiB;QAC/D,CAAC,OAAO,CAAC,KAAK,GAAG,OAAO,CAAC,IAAI,CAAC,GAAG,OAAO,CAAC,IAAI,EAAE,oBAAoB;QACnE,OAAO,CAAC,MAAM,GAAG,OAAO,CAAC,oBAAoB;SAC9C,CAAC;QAEF,6CAA6C;QAC7C,MAAM,SAAS,GAAG,CAAC,CAAC,EAAE,EAAE,EAAE,EAAE,CAAC,CAAC;QAC9B,KAAK,MAAM,QAAQ,IAAI,SAAS,EAAE,CAAC;YACjC,IAAI,KAAK,IAAI,QAAQ,EAAE,CAAC;gBACtB,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,QAAQ,GAAG,CAAC,EAAE,KAAK,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;gBAC7E,MAAM,GAAG,GAAG,eAAe,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;gBACzC,QAAQ,CAAC,IAAI,CAAC,CAAC,OAAO,CAAC,KAAK,GAAG,GAAG,CAAC,GAAG,GAAG,CAAC,CAAC;YAC7C,CAAC;iBAAM,CAAC;gBACN,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACnB,CAAC;QACH,CAAC;QAED,qCAAqC;QACrC,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAG,EAAE,EAAE,CAAC;YAClC,IAAI,KAAK,IAAI,GAAG,EAAE,CAAC;gBACjB,MAAM,SAAS,GAAG,IAAI,CAAC,KAAK,GAAG,GAAG,CAAC,CAAC,KAAK,CAAC;gBAC1C,QAAQ,CAAC,IAAI,CAAC,CAAC,OAAO,CAAC,KAAK,GAAG,SAAS,CAAC,GAAG,SAAS,CAAC,CAAC;YACzD,CAAC;iBAAM,CAAC;gBACN,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YACnB,CAAC;QACH,CAAC;QAED,OAAO,QAAQ,CAAC;IAClB,CAAC;IAED;;OAEG;IACK,SAAS,CAAC,QAAoB,EAAE,OAAiB;QACvD,MAAM,CAAC,GAAG,QAAQ,CAAC,MAAM,CAAC;QAC1B,MAAM,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;QAE7D,MAAM,MAAM,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;QAC5C,MAAM,KAAK,GAAG,QAAQ,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;QACxC,MAAM,MAAM,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC;QAC3C,MAAM,KAAK,GAAG,OAAO,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;QAEvC,OAAO,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,CAAC;IAC1C,CAAC;IAED;;OAEG;IACK,KAAK,CAAC,aAAa,CAAC,MAAkB,EAAE,MAAgB;QAC9D,IAAI,CAAC,MAAM,GAAG,EAAE,CAAC;QACjB,IAAI,CAAC,YAAY,GAAG,EAAE,CAAC;QAEvB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,YAAY,EAAE,CAAC,EAAE,EAAE,CAAC;YACnD,OAAO,CAAC,GAAG,CAAC,kBAAkB,CAAC,GAAG,CAAC,IAAI,IAAI,CAAC,OAAO,CAAC,YAAY,KAAK,CAAC,CAAC;YAEvE,MAAM,KAAK,GAAG,MAAM,IAAI,CAAC,gBAAgB,CAAC,MAAM,EAAE,MAAM,EAAE,CAAC,CAAC,CAAC;YAC7D,MAAM,MAAM,GAAG,IAAI,CAAC,oBAAoB,CAAC,KAAK,EAAE,MAAM,EAAE,MAAM,CAAC,CAAC;YAEhE,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;YACxB,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QACjC,CAAC;QAED,oBAAoB;QACpB,MAAM,WAAW,GAAG,eAAe,CAAC,GAAG,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;QAC3D,IAAI,WAAW,GAAG,CAAC,EAAE,CAAC;YACpB,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,WAAW,CAAC,CAAC;QAClE,CAAC;aAAM,CAAC;YACN,IAAI,CAAC,YAAY,GAAG,IAAI,KAAK,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,CAAC,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;QACjF,CAAC;IACH,CAAC;IAED;;OAEG;IACK,KAAK,CAAC,gBAAgB,CAAC,MAAkB,EAAE,MAAgB,EAAE,UAAkB;QACrF,mCAAmC;QACnC,MAAM,EAAE,QAAQ,EAAE,QAAQ,EAAE,GAAG,IAAI,CAAC,eAAe,CAAC,MAAM,EAAE,MAAM,EAAE,UAAU,CAAC,CAAC;QAEhF,gFAAgF;QAChF,MAAM,KAAK,GAAG,IAAI,CAAC,qBAAqB,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC;QAE7D,OAAO;YACL,IAAI,EAAE,QAAQ;YACd,YAAY,EAAE,KAAK,CAAC,YAAY;YAChC,SAAS,EAAE,KAAK,CAAC,SAAS;YAC1B,IAAI,EAAE,UAAU,GAAG,EAAE;SACtB,CAAC;IACJ,CAAC;IAED;;OAEG;IACK,qBAAqB,CAAC,CAAa,EAAE,CAAW;QACtD,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,MAAM,IAAI,CAAC,CAAC;QAE5B,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC;YACvB,OAAO,EAAE,YAAY,EAAE,EAAE,EAAE,SAAS,EAAE,CAAC,EAAE,CAAC;QAC5C,CAAC;QAED,uBAAuB;QACvB,MAAM,cAAc,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC,CAAC;QAEjD,qCAAqC;QACrC,8CAA8C;QAC9C,MAAM,YAAY,GAAG,IAAI,KAAK,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QAC1C,IAAI,SAAS,GAAG,eAAe,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QAExC,wCAAwC;QACxC,KAAK,IAAI,OAAO,GAAG,CAAC,EAAE,OAAO,GAAG,CAAC,EAAE,OAAO,EAAE,EAAE,CAAC;YAC7C,MAAM,aAAa,GAAG,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,OAAO,CAAC,CAAC,CAAC;YACjD,MAAM,WAAW,GAAG,SAAS,CAAC,WAAW,CAAC,aAAa,EAAE,CAAC,CAAC,CAAC;YAC5D,YAAY,CAAC,OAAO,CAAC,GAAG,WAAW,GAAG,GAAG,CAAC,CAAC,yBAAyB;QACtE,CAAC;QAED,OAAO,EAAE,YAAY,EAAE,SAAS,EAAE,CAAC;IACrC,CAAC;IAED;;OAEG;IACK,eAAe,CAAC,CAAa,EAAE,CAAW,EAAE,IAAY;QAC9D,MAAM,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC;QACnB,MAAM,QAAQ,GAAe,EAAE,CAAC;QAChC,MAAM,QAAQ,GAAa,EAAE,CAAC;QAE9B,uCAAuC;QACvC,IAAI,MAAM,GAAG,IAAI,CAAC;QAClB,MAAM,UAAU,GAAG,GAAG,EAAE;YACtB,MAAM,GAAG,CAAC,MAAM,GAAG,IAAI,GAAG,KAAK,CAAC,GAAG,MAAM,CAAC;YAC1C,OAAO,MAAM,GAAG,MAAM,CAAC;QACzB,CAAC,CAAC;QAEF,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC;YAC3B,MAAM,WAAW,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,EAAE,GAAG,CAAC,CAAC,CAAC;YACjD,QAAQ,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC;YACnC,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC,WAAW,CAAC,CAAC,CAAC;QAChC,CAAC;QAED,OAAO,EAAE,QAAQ,EAAE,QAAQ,EAAE,CAAC;IAChC,CAAC;IAED;;OAEG;IACK,oBAAoB,CAAC,KAAU,EAAE,CAAa,EAAE,CAAW;QACjE,MAAM,WAAW,GAAG,CAAC,CAAC,GAAG,CAAC,QAAQ,CAAC,EAAE,CAAC,IAAI,CAAC,gBAAgB,CAAC,KAAK,EAAE,QAAQ,EAAE,CAAC,CAAC,CAAC,CAAC;QACjF,MAAM,GAAG,GAAG,eAAe,CAAC,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAC,EAAE,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAEzF,yCAAyC;QACzC,OAAO,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACrC,CAAC;IAED;;OAEG;IACK,gBAAgB,CAAC,KAAU,EAAE,QAAkB,EAAE,UAAkB;QACzE,IAAI,KAAK,CAAC,IAAI,KAAK,QAAQ,EAAE,CAAC;YAC5B,IAAI,UAAU,GAAG,KAAK,CAAC,SAAS,CAAC;YACjC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAM,EAAE,KAAK,CAAC,YAAY,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC9E,UAAU,IAAI,QAAQ,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;YACpD,CAAC;YACD,OAAO,UAAU,CAAC;QACpB,CAAC;QAED,OAAO,CAAC,CAAC;IACX,CAAC;IAED;;OAEG;IACK,kBAAkB,CAAC,WAAqB;QAC9C,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC;YAAE,OAAO,CAAC,CAAC;QAEvC,mBAAmB;QACnB,IAAI,WAAW,GAAG,CAAC,CAAC;QACpB,IAAI,WAAW,GAAG,CAAC,CAAC;QAEpB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC;YAC5C,MAAM,MAAM,GAAG,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,GAAG,WAAW,CAAC,MAAM,CAAC,CAAC;YAChE,WAAW,IAAI,WAAW,CAAC,CAAC,CAAC,GAAG,MAAM,CAAC;YACvC,WAAW,IAAI,MAAM,CAAC;QACxB,CAAC;QAED,OAAO,WAAW,GAAG,CAAC,CAAC,CAAC,CAAC,WAAW,GAAG,WAAW,CAAC,CAAC,CAAC,eAAe,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;IACzF,CAAC;IAED;;OAEG;IACK,6BAA6B,CAAC,WAAqB;QACzD,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC;YAAE,OAAO,CAAC,CAAC;QAEvC,MAAM,IAAI,GAAG,eAAe,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;QAC/C,MAAM,GAAG,GAAG,eAAe,CAAC,iBAAiB,CAAC,WAAW,CAAC,CAAC;QAE3D,qDAAqD;QACrD,MAAM,aAAa,GAAG,GAAG,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,CAAC;QACpD,MAAM,UAAU,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,GAAG,aAAa,CAAC,CAAC,CAAC;QAE/D,OAAO,UAAU,CAAC;IACpB,CAAC;IAED;;OAEG;IACK,0BAA0B,CAAC,YAAoB;QACrD,4CAA4C;QAC5C,IAAI,CAAC,iBAAiB,GAAG,IAAI,KAAK,CAAC,YAAY,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;QAEzD,wDAAwD;QACxD,KAAK,MAAM,KAAK,IAAI,IAAI,CAAC,MAAM,EAAE,CAAC;YAChC,IAAI,KAAK,CAAC,YAAY,EAAE,CAAC;gBACvB,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,YAAY,EAAE,KAAK,CAAC,YAAY,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC;oBAC3E,IAAI,CAAC,iBAAiB,CAAC,CAAC,CAAC,IAAI,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;gBAC/D,CAAC;YACH,CAAC;QACH,CAAC;QAED,YAAY;QACZ,MAAM,KAAK,GAAG,eAAe,CAAC,GAAG,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;QAC1D,IAAI,KAAK,GAAG,CAAC,EAAE,CAAC;YACd,IAAI,CAAC,iBAAiB,GAAG,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,KAAK,CAAC,CAAC;QAC1E,CAAC;IACH,CAAC;IAED;;OAEG;IACK,gBAAgB,CAAC,WAAqB,EAAE,MAAgB;QAC9D,MAAM,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,WAAW,CAAC,MAAM,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;QACtD,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC;YACZ,OAAO;gBACL,GAAG,EAAE,CAAC;gBACN,GAAG,EAAE,CAAC;gBACN,IAAI,EAAE,CAAC;gBACP,EAAE,EAAE,CAAC;gBACL,mBAAmB,EAAE,GAAG;gBACxB,WAAW,EAAE,CAAC;aACf,CAAC;QACJ,CAAC;QAED,MAAM,IAAI,GAAG,WAAW,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QACrC,MAAM,GAAG,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAE/B,sBAAsB;QACtB,MAAM,GAAG,GAAG,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAE3E,yBAAyB;QACzB,MAAM,GAAG,GAAG,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9E,MAAM,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAE5B,YAAY;QACZ,MAAM,UAAU,GAAG,eAAe,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAC7C,MAAM,eAAe,GAAG,eAAe,CAAC,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QACvF,MAAM,kBAAkB,GAAG,eAAe,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE,CAAC,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5F,MAAM,EAAE,GAAG,eAAe,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,kBAAkB,GAAG,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAEhF,uBAAuB;QACvB,MAAM,iBAAiB,GAAG,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAE;YAC7C,OAAO,CAAC,CAAC,GAAG,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,IAAI,IAAI,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC;QAC3G,CAAC,CAAC,CAAC,MAAM,CAAC;QACV,MAAM,mBAAmB,GAAG,iBAAiB,GAAG,CAAC,CAAC;QAElD,OAAO;YACL,GAAG;YACH,GAAG;YACH,IAAI;YACJ,EAAE;YACF,mBAAmB;YACnB,WAAW,EAAE,CAAC;SACf,CAAC;IACJ,CAAC;IAED;;OAEG;IACK,cAAc,CAAC,KAAU;QAC/B,OAAO;YACL,IAAI,EAAE,KAAK,CAAC,IAAI;YAChB,YAAY,EAAE,KAAK,CAAC,YAAY;YAChC,SAAS,EAAE,KAAK,CAAC,SAAS;YAC1B,IAAI,EAAE,KAAK,CAAC,IAAI;SACjB,CAAC;IACJ,CAAC;IAED;;OAEG;IACK,gBAAgB,CAAC,eAAoB;QAC3C,OAAO;YACL,IAAI,EAAE,eAAe,CAAC,IAAI;YAC1B,YAAY,EAAE,eAAe,CAAC,YAAY,IAAI,EAAE;YAChD,SAAS,EAAE,eAAe,CAAC,SAAS,IAAI,CAAC;YACzC,IAAI,EAAE,eAAe,CAAC,IAAI,IAAI,CAAC;SAChC,CAAC;IACJ,CAAC;CACF\"}","dtsmap":{"name":"C:/Users/Ishaan/OneDrive/Desktop/MeridianLearning/meridianalgo-js/node_modules/.cache/rollup-plugin-typescript2/placeholder/predictors/UltraPrecisionPredictor.d.ts.map","writeByteOrderMark":false,"text":"{\"version\":3,\"file\":\"UltraPrecisionPredictor.d.ts\",\"sourceRoot\":\"\",\"sources\":[\"../../../../../src/predictors/UltraPrecisionPredictor.ts\"],\"names\":[],\"mappings\":\"AAAA;;;;;GAKG;AAEH,OAAO,EAAE,gBAAgB,EAAE,YAAY,EAAoB,YAAY,EAAE,eAAe,EAAE,MAAM,qBAAqB,CAAC;AAOtH;;GAEG;AACH,qBAAa,uBAAuB;IAClC,OAAO,CAAC,OAAO,CAA6B;IAC5C,OAAO,CAAC,MAAM,CAAa;IAC3B,OAAO,CAAC,SAAS,CAAkB;IACnC,OAAO,CAAC,iBAAiB,CAAgB;IACzC,OAAO,CAAC,eAAe,CAA6B;IACpD,OAAO,CAAC,cAAc,CAAa;IACnC,OAAO,CAAC,YAAY,CAAgB;gBAExB,OAAO,GAAE,OAAO,CAAC,gBAAgB,CAAM;IAOnD;;OAEG;IACG,KAAK,CAAC,IAAI,EAAE,YAAY,EAAE,GAAG,OAAO,CAAC,eAAe,CAAC;IAoD3D;;OAEG;IACG,OAAO,CAAC,QAAQ,EAAE,MAAM,EAAE,GAAG,OAAO,CAAC,MAAM,CAAC;IA6BlD;;OAEG;IACG,YAAY,CAAC,cAAc,EAAE,MAAM,EAAE,EAAE,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC;IAejE;;OAEG;IACH,aAAa,IAAI,MAAM;IAIvB;;OAEG;IACH,oBAAoB,IAAI,MAAM,EAAE;IAIhC;;OAEG;IACH,kBAAkB,IAAI,YAAY,GAAG,IAAI;IAIzC;;OAEG;IACH,cAAc,IAAI,OAAO;IAIzB;;OAEG;IACG,SAAS,IAAI,OAAO,CAAC,MAAM,CAAC;IAkBlC;;OAEG;IACG,SAAS,CAAC,SAAS,EAAE,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC;IAsBjD;;OAEG;IACH,OAAO,CAAC,mBAAmB;IA+B3B;;OAEG;IACH,OAAO,CAAC,qBAAqB;IAoC7B;;OAEG;IACH,OAAO,CAAC,SAAS;IAYjB;;OAEG;YACW,aAAa;IAuB3B;;OAEG;YACW,gBAAgB;IAe9B;;OAEG;IACH,OAAO,CAAC,qBAAqB;IA0B7B;;OAEG;IACH,OAAO,CAAC,eAAe;IAqBvB;;OAEG;IACH,OAAO,CAAC,oBAAoB;IAQ5B;;OAEG;IACH,OAAO,CAAC,gBAAgB;IAYxB;;OAEG;IACH,OAAO,CAAC,kBAAkB;IAgB1B;;OAEG;IACH,OAAO,CAAC,6BAA6B;IAarC;;OAEG;IACH,OAAO,CAAC,0BAA0B;IAoBlC;;OAEG;IACH,OAAO,CAAC,gBAAgB;IA6CxB;;OAEG;IACH,OAAO,CAAC,cAAc;IAStB;;OAEG;IACH,OAAO,CAAC,gBAAgB;CAQzB\"}"},"dts":{"name":"C:/Users/Ishaan/OneDrive/Desktop/MeridianLearning/meridianalgo-js/node_modules/.cache/rollup-plugin-typescript2/placeholder/predictors/UltraPrecisionPredictor.d.ts","writeByteOrderMark":false,"text":"/**\n * Ultra-Precision Predictor\n *\n * Advanced ensemble predictor targeting sub-1% error rates through\n * sophisticated feature engineering and model combination.\n */\nimport { PredictorOptions, TrainingData, ModelMetrics, TrainingResults } from '../types/Prediction';\n/**\n * Ultra-precision predictor implementation\n */\nexport declare class UltraPrecisionPredictor {\n    private options;\n    private models;\n    private isTrained;\n    private featureImportance;\n    private trainingMetrics;\n    private lastConfidence;\n    private modelWeights;\n    constructor(options?: Partial<PredictorOptions>);\n    /**\n     * Train the ultra-precision predictor\n     */\n    train(data: TrainingData[]): Promise<TrainingResults>;\n    /**\n     * Make ultra-precise prediction\n     */\n    predict(features: number[]): Promise<number>;\n    /**\n     * Batch prediction for multiple samples\n     */\n    predictBatch(featuresMatrix: number[][]): Promise<number[]>;\n    /**\n     * Get prediction confidence (0-1)\n     */\n    getConfidence(): number;\n    /**\n     * Get feature importance scores\n     */\n    getFeatureImportance(): number[];\n    /**\n     * Get training metrics\n     */\n    getTrainingMetrics(): ModelMetrics | null;\n    /**\n     * Check if model is trained\n     */\n    isModelTrained(): boolean;\n    /**\n     * Save model to JSON string\n     */\n    saveModel(): Promise<string>;\n    /**\n     * Load model from JSON string\n     */\n    loadModel(modelJson: string): Promise<void>;\n    /**\n     * Prepare training data from raw data\n     */\n    private prepareTrainingData;\n    /**\n     * Generate basic features from OHLCV data\n     */\n    private generateBasicFeatures;\n    /**\n     * Split data into training and testing sets\n     */\n    private splitData;\n    /**\n     * Train ensemble of models\n     */\n    private trainEnsemble;\n    /**\n     * Train a single model in the ensemble\n     */\n    private trainSingleModel;\n    /**\n     * Train a simple linear regression model\n     */\n    private trainLinearRegression;\n    /**\n     * Bootstrap sampling for ensemble diversity\n     */\n    private bootstrapSample;\n    /**\n     * Calculate model weight based on performance\n     */\n    private calculateModelWeight;\n    /**\n     * Make prediction with a single model\n     */\n    private predictWithModel;\n    /**\n     * Combine predictions from ensemble\n     */\n    private combinepredictions;\n    /**\n     * Calculate prediction confidence based on ensemble agreement\n     */\n    private calculatePredictionConfidence;\n    /**\n     * Calculate feature importance\n     */\n    private calculateFeatureImportance;\n    /**\n     * Calculate model performance metrics\n     */\n    private calculateMetrics;\n    /**\n     * Serialize model for saving\n     */\n    private serializeModel;\n    /**\n     * Deserialize model for loading\n     */\n    private deserializeModel;\n}\n//# sourceMappingURL=UltraPrecisionPredictor.d.ts.map"}}
